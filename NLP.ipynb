{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b33a541",
   "metadata": {},
   "source": [
    "pickle file -> binary file\n",
    "vene -> virtual environment \n",
    "\n",
    "home work\n",
    "-opencv\n",
    "-nltk\n",
    "-bot\n",
    "-webscrapping\n",
    "\n",
    "\n",
    "applications\n",
    "- face lock\n",
    "- snapchat \n",
    "\n",
    "detection\n",
    "\n",
    "to detect for anything \n",
    "\n",
    "we mainly use when prepare data\n",
    "- object\n",
    "- face \n",
    "\n",
    "recognization \n",
    "we use realtime to face match\n",
    "- face match\n",
    "\n",
    "opencv -> python , selnium, java , c# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f174e7",
   "metadata": {},
   "source": [
    "NLTK :\n",
    "\n",
    "- text \n",
    "- voice \n",
    "\n",
    "https://realpython.com/nltk-nlp-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fb9696",
   "metadata": {},
   "source": [
    "email \n",
    "- spam\n",
    "- ham (impt email)\n",
    "\n",
    "1. tokenization : by words or sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cf5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"science, any system of knowledge that is concerned with the physical world and its phenomena and that entails unbiased observations and systematic experimentation. In general,\n",
    "a science involves a pursuit of knowledge covering general truths or the operations of fundamental laws.\n",
    "All peoples have studied the natural world, but most ancient peoples studied it for practical purposes, such as paying attention to natural cycles to know when to plant crops. It does not seem to have been until the 6th century BCE \n",
    "that the pre-Socratic philosophers (who lived in what is now Turkey and Greece) began seeking to understand nature as an end in itself.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cc4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36495422",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a074bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "worf_quote = \"Sir, I protest. I am not a merry man!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_quote = word_tokenize(worf_quote)\n",
    "words_in_quote\n",
    "['Sir', ',', 'protest', '.', 'merry', 'man', '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916ef385",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff46f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b11de8",
   "metadata": {},
   "outputs": [],
   "source": [
    " for word in words_in_quote:\n",
    "        if word.casefold() not in stop_words:\n",
    "            filtered_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e8d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    " filtered_list = [ word for word in words_in_quote if word.casefold() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b78876",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4537d69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a82b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_for_stemming = \"\"\"\n",
    "The crew of the USS Discovery discovered many discoveries.\n",
    "Discovering is what explorers do.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(string_for_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f55cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list have comprehension \n",
    "stemmed_words = [stemmer.stem(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a43502",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20200739",
   "metadata": {},
   "source": [
    " # Tagging Parts of Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecf7d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sobia\\appdata\\roaming\\python\\python39\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39893464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be277288",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_quote = \"\"\"If you wish to make an apple pie from scratch,\n",
    "you must first invent the universe.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4da3b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_a_quote = word_tokenize(a_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a183408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading avraged_perceptron_tagger: Package\n",
      "[nltk_data]     'avraged_perceptron_tagger' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('avraged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc50d546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3366ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sobia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9981c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.pos_tag(words_in_a_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd151a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'DT'), ('is', 'VBZ'), ('an', 'DT'), ('example', 'NN'), ('sentence', 'NN')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sobia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Now you can perform part-of-speech tagging\n",
    "words_in_a_quote = [\"This\", \"is\", \"an\", \"example\", \"sentence\"]\n",
    "tags = nltk.pos_tag(words_in_a_quote)\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80787863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out nouns in the passage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ee55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7950e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " for word in words_in_quote:\n",
    "        if word.casefold() not in stop_words:\n",
    "            filtered_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665da4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = [ word for word in words_in_quote if word.casefold() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b5d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37fffe0",
   "metadata": {},
   "source": [
    "1. get words\n",
    "2. looping in words\n",
    "3. check for noun \n",
    "4. append in noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf5ebfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = words_in_a_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ce5ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in word:\n",
    "    if i[1]=='NN':\n",
    "        noun.append(i[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a4e30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out nouns (NN and NNS)\n",
    "nouns = [word for word, tag in tags if tag in ['NN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46813260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['example', 'sentence']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c61d95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"\"\"Data science is an interdisciplinary academic field [1] that uses statistics, scientific computing, scientific methods, processes, algorithms and systems to extract or extrapolate knowledge and insights from noisy, structured, and unstructured data.[2]\n",
    "\n",
    "Data science also integrates domain knowledge from the underlying application domain (e.g., natural sciences, information technology, and medicine).[3] Data science is multifaceted and can be described as a science, a research paradigm, a research method, a discipline, a workflow, and a profession.[4]\n",
    "\n",
    "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" to \"understand and analyze actual phenomena\" with data.[5] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[6] However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[7][8]\n",
    "\n",
    "A data scientist is a professional who creates programming code and combines it with statistical knowledge to create insights from data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5d9055cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_a_x = word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1aaa9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Data', 'NNP'), ('science', 'NN'), ('is', 'VBZ'), ('an', 'DT'), ('interdisciplinary', 'JJ'), ('academic', 'JJ'), ('field', 'NN'), ('[', 'VBD'), ('1', 'CD'), (']', 'NN'), ('that', 'WDT'), ('uses', 'VBZ'), ('statistics', 'NNS'), (',', ','), ('scientific', 'JJ'), ('computing', 'NN'), (',', ','), ('scientific', 'JJ'), ('methods', 'NNS'), (',', ','), ('processes', 'NNS'), (',', ','), ('algorithms', 'NN'), ('and', 'CC'), ('systems', 'NNS'), ('to', 'TO'), ('extract', 'VB'), ('or', 'CC'), ('extrapolate', 'VB'), ('knowledge', 'NN'), ('and', 'CC'), ('insights', 'NNS'), ('from', 'IN'), ('noisy', 'NN'), (',', ','), ('structured', 'VBN'), (',', ','), ('and', 'CC'), ('unstructured', 'JJ'), ('data', 'NNS'), ('.', '.'), ('[', '$'), ('2', 'CD'), (']', 'NNP'), ('Data', 'NNP'), ('science', 'NN'), ('also', 'RB'), ('integrates', 'VBZ'), ('domain', 'VBP'), ('knowledge', 'NN'), ('from', 'IN'), ('the', 'DT'), ('underlying', 'VBG'), ('application', 'NN'), ('domain', 'NN'), ('(', '('), ('e.g.', 'NN'), (',', ','), ('natural', 'JJ'), ('sciences', 'NNS'), (',', ','), ('information', 'NN'), ('technology', 'NN'), (',', ','), ('and', 'CC'), ('medicine', 'NN'), (')', ')'), ('.', '.'), ('[', '$'), ('3', 'CD'), (']', 'NNP'), ('Data', 'NNP'), ('science', 'NN'), ('is', 'VBZ'), ('multifaceted', 'VBN'), ('and', 'CC'), ('can', 'MD'), ('be', 'VB'), ('described', 'VBN'), ('as', 'IN'), ('a', 'DT'), ('science', 'NN'), (',', ','), ('a', 'DT'), ('research', 'NN'), ('paradigm', 'NN'), (',', ','), ('a', 'DT'), ('research', 'NN'), ('method', 'NN'), (',', ','), ('a', 'DT'), ('discipline', 'NN'), (',', ','), ('a', 'DT'), ('workflow', 'NN'), (',', ','), ('and', 'CC'), ('a', 'DT'), ('profession', 'NN'), ('.', '.'), ('[', 'CC'), ('4', 'CD'), (']', 'NN'), ('Data', 'NNP'), ('science', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('``', '``'), ('concept', 'NN'), ('to', 'TO'), ('unify', 'VB'), ('statistics', 'NNS'), (',', ','), ('data', 'NNS'), ('analysis', 'NN'), (',', ','), ('informatics', 'NNS'), (',', ','), ('and', 'CC'), ('their', 'PRP$'), ('related', 'JJ'), ('methods', 'NNS'), (\"''\", \"''\"), ('to', 'TO'), ('``', '``'), ('understand', 'VB'), ('and', 'CC'), ('analyze', 'VB'), ('actual', 'JJ'), ('phenomena', 'NNS'), (\"''\", \"''\"), ('with', 'IN'), ('data', 'NNS'), ('.', '.'), ('[', '$'), ('5', 'CD'), (']', 'NN'), ('It', 'PRP'), ('uses', 'VBZ'), ('techniques', 'NNS'), ('and', 'CC'), ('theories', 'NNS'), ('drawn', 'VBP'), ('from', 'IN'), ('many', 'JJ'), ('fields', 'NNS'), ('within', 'IN'), ('the', 'DT'), ('context', 'NN'), ('of', 'IN'), ('mathematics', 'NNS'), (',', ','), ('statistics', 'NNS'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('information', 'NN'), ('science', 'NN'), (',', ','), ('and', 'CC'), ('domain', 'NN'), ('knowledge', 'NN'), ('.', '.'), ('[', 'CC'), ('6', 'CD'), (']', 'NN'), ('However', 'RB'), (',', ','), ('data', 'NNS'), ('science', 'NN'), ('is', 'VBZ'), ('different', 'JJ'), ('from', 'IN'), ('computer', 'NN'), ('science', 'NN'), ('and', 'CC'), ('information', 'NN'), ('science', 'NN'), ('.', '.'), ('Turing', 'VBG'), ('Award', 'NNP'), ('winner', 'NN'), ('Jim', 'NNP'), ('Gray', 'NNP'), ('imagined', 'VBD'), ('data', 'NNS'), ('science', 'NN'), ('as', 'IN'), ('a', 'DT'), ('``', '``'), ('fourth', 'JJ'), ('paradigm', 'NN'), (\"''\", \"''\"), ('of', 'IN'), ('science', 'NN'), ('(', '('), ('empirical', 'JJ'), (',', ','), ('theoretical', 'JJ'), (',', ','), ('computational', 'JJ'), (',', ','), ('and', 'CC'), ('now', 'RB'), ('data-driven', 'JJ'), (')', ')'), ('and', 'CC'), ('asserted', 'VBD'), ('that', 'IN'), ('``', '``'), ('everything', 'NN'), ('about', 'IN'), ('science', 'NN'), ('is', 'VBZ'), ('changing', 'VBG'), ('because', 'IN'), ('of', 'IN'), ('the', 'DT'), ('impact', 'NN'), ('of', 'IN'), ('information', 'NN'), ('technology', 'NN'), (\"''\", \"''\"), ('and', 'CC'), ('the', 'DT'), ('data', 'NNS'), ('deluge', 'NN'), ('.', '.'), ('[', 'CC'), ('7', 'CD'), (']', 'JJ'), ('[', '$'), ('8', 'CD'), (']', 'CC'), ('A', 'NNP'), ('data', 'NNS'), ('scientist', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('professional', 'JJ'), ('who', 'WP'), ('creates', 'VBZ'), ('programming', 'VBG'), ('code', 'NN'), ('and', 'CC'), ('combines', 'NNS'), ('it', 'PRP'), ('with', 'IN'), ('statistical', 'JJ'), ('knowledge', 'NN'), ('to', 'TO'), ('create', 'VB'), ('insights', 'NNS'), ('from', 'IN'), ('data', 'NNS')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sobia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "tags = nltk.pos_tag(words_in_a_x)\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e53c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = words_in_a_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46076a8e",
   "metadata": {},
   "source": [
    "## 1. Filter out nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "288c9cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nouns = [word for word, tag in tags if tag in ['NN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c080bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['science',\n",
       " 'field',\n",
       " ']',\n",
       " 'computing',\n",
       " 'algorithms',\n",
       " 'knowledge',\n",
       " 'noisy',\n",
       " 'science',\n",
       " 'knowledge',\n",
       " 'application',\n",
       " 'domain',\n",
       " 'e.g.',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'medicine',\n",
       " 'science',\n",
       " 'science',\n",
       " 'research',\n",
       " 'paradigm',\n",
       " 'research',\n",
       " 'method',\n",
       " 'discipline',\n",
       " 'workflow',\n",
       " 'profession',\n",
       " ']',\n",
       " 'science',\n",
       " 'concept',\n",
       " 'analysis',\n",
       " ']',\n",
       " 'context',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'information',\n",
       " 'science',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " ']',\n",
       " 'science',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'information',\n",
       " 'science',\n",
       " 'winner',\n",
       " 'science',\n",
       " 'paradigm',\n",
       " 'science',\n",
       " 'everything',\n",
       " 'science',\n",
       " 'impact',\n",
       " 'information',\n",
       " 'technology',\n",
       " 'deluge',\n",
       " 'scientist',\n",
       " 'code',\n",
       " 'knowledge']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf1fbd",
   "metadata": {},
   "source": [
    "## 2. filter out helping verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53890cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out nouns (NN and NNS)\n",
    "helpingverb = [word for word, tag in tags if tag in ['VBZ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a1ee49c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'uses', 'integrates', 'is', 'is', 'uses', 'is', 'is', 'is', 'creates']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helpingverb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ad981",
   "metadata": {},
   "source": [
    "## 3. composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "870e0ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinecomposition = [word for word, tag in tags if tag in ['CC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daa53c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'or',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " '[',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " '[',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " '[',\n",
       " ']',\n",
       " 'and']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36851d",
   "metadata": {},
   "source": [
    "## 4. adjustive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5cb285e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adjuctive = [word for word, tag in tags if tag in ['JJ']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99b57139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['interdisciplinary',\n",
       " 'academic',\n",
       " 'scientific',\n",
       " 'scientific',\n",
       " 'unstructured',\n",
       " 'natural',\n",
       " 'related',\n",
       " 'actual',\n",
       " 'many',\n",
       " 'different',\n",
       " 'fourth',\n",
       " 'empirical',\n",
       " 'theoretical',\n",
       " 'computational',\n",
       " 'data-driven',\n",
       " ']',\n",
       " 'professional',\n",
       " 'statistical']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjuctive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73baf96",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb0d717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "325ae39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7afc4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\sobia\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b0d47b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scarf'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"scarves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b290abe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
